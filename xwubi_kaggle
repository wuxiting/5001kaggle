{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "train = pd.read_csv('data/train.csv') \n",
    "test = pd.read_csv('data/test.csv')\n",
    "ID = test['id']\n",
    "train.drop('id',axis=1,inplace = True)\n",
    "test.drop('id',axis=1,inplace = True) \n",
    "train['n_jobs'].replace(-1,16,inplace=True) \n",
    "test['n_jobs'].replace(-1,16,inplace=True)\n",
    "train.drop('random_state',axis=1,inplace = True)\n",
    "test.drop('random_state',axis=1,inplace = True)\n",
    "train.drop('scale',axis=1,inplace = True)\n",
    "test.drop('scale',axis=1,inplace = True)\n",
    "def fun2(x,y):\n",
    "    if x == 'elasticnet':\n",
    "        return y\n",
    "    elif x == 'l1':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['l1_ratio']= train.apply(lambda x: fun2(x.penalty,x.l1_ratio),axis=1)\n",
    "test['l1_ratio']= test.apply(lambda x: fun2(x.penalty,x.l1_ratio),axis=1)\n",
    "def fun1(x):\n",
    "    y = math.log(x)\n",
    "    return(y)\n",
    "# train['n_samples']= train['n_samples'].apply(lambda x: fun1(x))\n",
    "# test['n_samples']= test['n_samples'].apply(lambda x: fun1(x))\n",
    "# train['n_features']= train['n_features'].apply(lambda x: fun1(x))\n",
    "# test['n_features']= test['n_features'].apply(lambda x: fun1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun4(x,y):\n",
    "    z = x*y\n",
    "    return(z)\n",
    "train['n_cluster']= train.apply(lambda x: fun4(x.n_clusters_per_class,x.n_classes),axis=1)\n",
    "test['n_cluster']= test.apply(lambda x: fun4(x.n_clusters_per_class,x.n_classes),axis=1)\n",
    "def fun5(x,y,z,q):\n",
    "    w = x*y*z/q\n",
    "    return(w)\n",
    "train['total']= train.apply(lambda x: fun5(x.n_samples,x.n_features,x.max_iter,x.n_jobs),axis=1)\n",
    "test['total']= test.apply(lambda x: fun5(x.n_samples,x.n_features,x.max_iter,x.n_jobs),axis=1)\n",
    "train.drop('n_samples',axis=1,inplace = True)\n",
    "test.drop('n_samples',axis=1,inplace = True)\n",
    "train.drop('n_features',axis=1,inplace = True)\n",
    "test.drop('n_features',axis=1,inplace = True)\n",
    "train.drop('max_iter',axis=1,inplace = True)\n",
    "test.drop('max_iter',axis=1,inplace = True)\n",
    "train.drop('n_informative',axis=1,inplace = True)\n",
    "test.drop('n_informative',axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train['time'] = train['time'].apply(lambda x: fun1(x))\n",
    "train_Y = train['time']\n",
    "train.drop('time',axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>2.974047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_l2</th>\n",
       "      <td>1.334375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_l1</th>\n",
       "      <td>1.217562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_none</th>\n",
       "      <td>1.094306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>1.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_elasticnet</th>\n",
       "      <td>0.993824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cluster</th>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.677777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_ratio</th>\n",
       "      <td>0.491777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_clusters_per_class</th>\n",
       "      <td>0.096758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flip_y</th>\n",
       "      <td>0.071185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_classes</th>\n",
       "      <td>0.047920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Skew\n",
       "total                 2.974047\n",
       "penalty_l2            1.334375\n",
       "penalty_l1            1.217562\n",
       "penalty_none          1.094306\n",
       "n_jobs                1.003699\n",
       "penalty_elasticnet    0.993824\n",
       "n_cluster             0.836670\n",
       "alpha                 0.677777\n",
       "l1_ratio              0.491777\n",
       "n_clusters_per_class  0.096758\n",
       "flip_y                0.071185\n",
       "n_classes             0.047920"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    train[feat] = boxcox1p(train[feat], lam)\n",
    "    test[feat] = boxcox1p(test[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "mean = train.mean(axis=0)         #normalize features\n",
    "std = train.std(axis=0)\n",
    "train = (train - mean) / std\n",
    "test = (test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1664      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,337\n",
      "Trainable params: 22,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu,\n",
    "                       input_shape=(train.shape[1],)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(32, activation=tf.nn.softplus),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    #optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "    return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "# Store training stats\n",
    "history = model.fit(train, train_Y, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(train, train_Y, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test).flatten()\n",
    "submission = pd.DataFrame({'Id': ID,'time': predictions})\n",
    "def fun3(x):\n",
    "    y = math.exp(x)\n",
    "    return(y)\n",
    "submission['time']= submission['time'].apply(lambda x: fun3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./outcome.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.959488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.065499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.407535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.106230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.250327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.378166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.764296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.549871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>14.535785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.344219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.685283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>13.127743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.558172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>31.383930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.498743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.751250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.918788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5.944129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3.783129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.045569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.347016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.373513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.529055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.567331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.303629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.274734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.042263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2.350181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.547669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2.653558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0.374418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.706864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>9.826038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0.256867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>6.328788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>4.612274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>1.154911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>3.878807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>3.880177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>1.007385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>8.139006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>4.275723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>5.208325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.972890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>1.396751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>3.491832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>5.265176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0.399715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>5.246468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>1.023022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>3.684904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.862947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>1.380496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>10.980163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>9.263261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>3.606350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>47.065133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.320381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.693166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.193546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id       time\n",
       "0    0   0.959488\n",
       "1    1   9.065499\n",
       "2    2   0.407535\n",
       "3    3   1.106230\n",
       "4    4   2.250327\n",
       "5    5   7.378166\n",
       "6    6   2.764296\n",
       "7    7   0.549871\n",
       "8    8  14.535785\n",
       "9    9   0.344219\n",
       "10  10   5.685283\n",
       "11  11  13.127743\n",
       "12  12   0.558172\n",
       "13  13  31.383930\n",
       "14  14   0.498743\n",
       "15  15   0.751250\n",
       "16  16   0.918788\n",
       "17  17   5.944129\n",
       "18  18   3.783129\n",
       "19  19   1.045569\n",
       "20  20   0.347016\n",
       "21  21   0.373513\n",
       "22  22   0.529055\n",
       "23  23   0.567331\n",
       "24  24   1.303629\n",
       "25  25   1.274734\n",
       "26  26   1.042263\n",
       "27  27   2.350181\n",
       "28  28   1.547669\n",
       "29  29   2.653558\n",
       "..  ..        ...\n",
       "70  70   0.374418\n",
       "71  71   0.706864\n",
       "72  72   9.826038\n",
       "73  73   0.256867\n",
       "74  74   6.328788\n",
       "75  75   4.612274\n",
       "76  76   1.154911\n",
       "77  77   3.878807\n",
       "78  78   3.880177\n",
       "79  79   1.007385\n",
       "80  80   8.139006\n",
       "81  81   4.275723\n",
       "82  82   5.208325\n",
       "83  83   0.972890\n",
       "84  84   1.396751\n",
       "85  85   3.491832\n",
       "86  86   5.265176\n",
       "87  87   0.399715\n",
       "88  88   5.246468\n",
       "89  89   1.023022\n",
       "90  90   3.684904\n",
       "91  91   0.862947\n",
       "92  92   1.380496\n",
       "93  93  10.980163\n",
       "94  94   9.263261\n",
       "95  95   3.606350\n",
       "96  96  47.065133\n",
       "97  97   0.320381\n",
       "98  98   0.693166\n",
       "99  99   0.193546\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
